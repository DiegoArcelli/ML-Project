{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "18594d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# deep learning\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "087d274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monk1_train = pd.read_csv('data/monks-1.train',header=None,sep=\" \")\n",
    "monk1_test = pd.read_csv('data/monks-1.test',header=None,sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "04758145",
   "metadata": {},
   "outputs": [],
   "source": [
    "monk1_train.drop(0,axis=1,inplace=True)\n",
    "monk1_train.drop(8,axis=1,inplace=True)\n",
    "\n",
    "monk1_test.drop(0,axis=1,inplace=True)\n",
    "monk1_test.drop(8,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "0fc9631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = monk1_train.iloc[:,1:]\n",
    "ytr = monk1_train.iloc[:,0]\n",
    "\n",
    "xts = monk1_test.iloc[:,1:]\n",
    "yts = monk1_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "4543e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "9ab50fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "xtr = scaler.fit_transform(xtr)\n",
    "xts = scaler.fit_transform(xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "7e4b1e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "7396e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xvl, ytr, yvl = train_test_split(xtr, ytr, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "df832731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = ytr.to_numpy()\n",
    "yvl = yvl.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "98c5e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "48588777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMonk(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim, hidden1, learning_rate):\n",
    "        super(ClassificationMonk, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.linear1 = nn.Linear(input_dim, hidden1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        # Second hidden layer\n",
    "        self.linear2 = nn.Linear(hidden1, hidden1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        # Third hidden layer\n",
    "        self.linear3 = nn.Linear(hidden1,output_dim)\n",
    "        self.act3 = nn.Sigmoid()\n",
    "        self.loss_fun = nn.MSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def forward(self, X):\n",
    "        #Input to the first hidden layer\n",
    "        X = self.linear1(X)\n",
    "        X = self.act1(X)\n",
    "        # Second hidden layer\n",
    "        X = self.linear2(X)\n",
    "        X = self.act2(X)\n",
    "        # Third hidden layer\n",
    "        X = self.linear3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch  #1\n",
    "        X = X.type(torch.float32)\n",
    "        y = y.type(torch.float32)  #2\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()  #3 \n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)  \n",
    "        self.log_dict({'train_loss': loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, validation_batch, batch_idx):\n",
    "        X, y = validation_batch\n",
    "        #y = y.type(torch.float32)\n",
    "        X = X.type(torch.float32)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()        \n",
    "        # compute metrics       \n",
    "        print(y_pred) \n",
    "        accuracy = Accuracy()\n",
    "        acc = accuracy(y_pred, y)\n",
    "        loss = self.loss_fun(y_pred[0], y[0])\n",
    "        self.log_dict({'validation_loss': loss, 'accuracy': acc}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        #y = y.type(torch.float32)\n",
    "        X = X.type(torch.float32)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()        \n",
    "        # compute metrics       \n",
    "        print(y_pred) \n",
    "        accuracy = Accuracy()\n",
    "        acc = accuracy(y_pred, y)\n",
    "        loss = self.loss_fun(y_pred[0], y[0])\n",
    "        self.log_dict({'test_loss': loss, 'accuracy': acc}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "87c67bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = 20  \n",
    "max_epochs = 500  \n",
    "lr = 0.01\n",
    "train_batch_size = 20  \n",
    "validation_batch_size = 20  \n",
    "test_batch_size = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "952d536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instance\n",
    "input_dim = xtr.shape[1]\n",
    "model = ClassificationMonk(input_dim=input_dim, output_dim=1, hidden1=hidden1, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "3ebd185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMonkDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "f834b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = ClassificationMonkDataset(xtr, ytr), batch_size=train_batch_size)\n",
    "validation_loader = DataLoader(dataset = ClassificationMonkDataset(xvl, yvl), batch_size=validation_batch_size)\n",
    "test_loader = DataLoader(dataset = ClassificationMonkDataset(xts, yts), batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "48c47c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.0001, patience=10, verbose=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "a0f228d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/dylan/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/Users/dylan/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a9825b080f434f8771f5a6174cb5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.04365158322401657\n",
      "Restoring states from the checkpoint path at /Users/dylan/Desktop/ML-Project/.lr_find_59bc2518-b4d5-4187-b72e-949fe041d609.ckpt\n",
      "Restored all states from the checkpoint file at /Users/dylan/Desktop/ML-Project/.lr_find_59bc2518-b4d5-4187-b72e-949fe041d609.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr_find': <pytorch_lightning.tuner.lr_finder._LRFinder at 0x29c13e850>}"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='cpu', devices=1, max_epochs=max_epochs, callbacks=[early_stop_callback], log_every_n_steps=5,auto_lr_find=True)  \n",
    "trainer.tune(model=model, train_dataloaders=train_loader) #for auto_lr_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "54804929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | linear1  | Linear  | 140   \n",
      "1 | act1     | ReLU    | 0     \n",
      "2 | linear2  | Linear  | 420   \n",
      "3 | act2     | ReLU    | 0     \n",
      "4 | linear3  | Linear  | 21    \n",
      "5 | act3     | Sigmoid | 0     \n",
      "6 | loss_fun | MSELoss | 0     \n",
      "-------------------------------------\n",
      "581       Trainable params\n",
      "0         Non-trainable params\n",
      "581       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58afb96119e452aa5aeda051d5cd1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 0.243\n",
      "Metric train_loss improved by 0.060 >= min_delta = 0.0001. New best score: 0.183\n",
      "Metric train_loss improved by 0.034 >= min_delta = 0.0001. New best score: 0.149\n",
      "Metric train_loss improved by 0.038 >= min_delta = 0.0001. New best score: 0.111\n",
      "Metric train_loss improved by 0.027 >= min_delta = 0.0001. New best score: 0.084\n",
      "Metric train_loss improved by 0.025 >= min_delta = 0.0001. New best score: 0.059\n",
      "Metric train_loss improved by 0.020 >= min_delta = 0.0001. New best score: 0.039\n",
      "Metric train_loss improved by 0.019 >= min_delta = 0.0001. New best score: 0.019\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0001. New best score: 0.007\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.004\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.002\n",
      "Monitored metric train_loss did not improve in the last 10 records. Best score: 0.002. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=train_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "d36d5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c4de703a7a4f23ae7e94202e78edc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0371e-03, 1.2767e-07, 1.0000e+00, 1.0000e+00, 1.3615e-03, 1.1458e-06,\n",
      "        2.2357e-05, 9.7660e-01, 1.0000e+00, 9.9996e-01, 3.9034e-10, 1.0000e+00,\n",
      "        3.0495e-07])\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        accuracy                    1.0\n",
      "        test_loss         1.0755005632745451e-06\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.0755005632745451e-06, 'accuracy': 1.0}]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=model, dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "d3775f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ccc12518f248d7983cf876b9a80441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 0.9934, 0.9983, 0.9065, 0.9973, 0.8012, 0.9904, 1.0000,\n",
      "        1.0000, 0.9568, 0.9887, 0.2475, 0.9771, 0.1141, 0.9692, 1.0000, 1.0000,\n",
      "        0.9083, 0.9961])\n",
      "tensor([0.4295, 0.9816, 0.2289, 0.9829, 1.0000, 1.0000, 1.0000, 0.9999, 0.9993,\n",
      "        0.9999, 0.9987, 0.9999, 1.0000, 1.0000, 0.9999, 0.9984, 0.9972, 0.9986,\n",
      "        0.9733, 0.9976])\n",
      "tensor([1.0000e+00, 1.0000e+00, 9.9847e-01, 9.9816e-01, 9.6983e-01, 9.9470e-01,\n",
      "        8.2882e-01, 9.8847e-01, 1.0000e+00, 1.0000e+00, 1.1950e-05, 2.5811e-04,\n",
      "        7.7199e-06, 1.9543e-04, 1.0448e-05, 2.1890e-04, 1.0000e+00, 1.0000e+00,\n",
      "        8.3878e-06, 2.7646e-04])\n",
      "tensor([1.2547e-06, 1.1987e-04, 8.4945e-07, 1.3237e-04, 1.0000e+00, 1.0000e+00,\n",
      "        1.7411e-05, 1.3430e-03, 1.3302e-06, 1.8705e-04, 1.3442e-06, 1.8297e-04,\n",
      "        1.0000e+00, 1.0000e+00, 6.6016e-03, 1.7659e-02, 6.8745e-04, 2.8695e-02,\n",
      "        5.1183e-03, 2.3396e-01])\n",
      "tensor([1.0000e+00, 1.0000e+00, 3.3505e-03, 3.9531e-03, 6.1244e-05, 1.6376e-03,\n",
      "        3.9550e-04, 4.4286e-03, 1.0000e+00, 1.0000e+00, 4.0872e-03, 1.4782e-02,\n",
      "        3.4640e-05, 2.4049e-03, 5.3852e-05, 6.9757e-03, 1.0000e+00, 1.0000e+00,\n",
      "        3.3196e-10, 2.3416e-08])\n",
      "tensor([1.4627e-10, 7.9711e-10, 9.3598e-11, 1.8618e-09, 1.0000e+00, 1.0000e+00,\n",
      "        1.7302e-10, 1.8674e-08, 5.5703e-11, 5.0629e-10, 4.2481e-11, 1.0958e-09,\n",
      "        1.0000e+00, 1.0000e+00, 2.6580e-10, 6.2271e-08, 2.6958e-11, 6.0616e-10,\n",
      "        2.3174e-11, 1.7840e-09])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.2733e-08, 6.3747e-08, 5.6998e-09, 1.0836e-07,\n",
      "        4.5219e-08, 1.3498e-06, 1.0000e+00, 1.0000e+00, 1.2053e-08, 2.3752e-08,\n",
      "        2.8147e-09, 2.1855e-08, 4.8687e-09, 9.7950e-08, 1.0000e+00, 1.0000e+00,\n",
      "        1.2315e-08, 3.5381e-08])\n",
      "tensor([1.0585e-09, 2.4209e-08, 1.0265e-09, 6.9566e-08, 1.0000e+00, 1.0000e+00,\n",
      "        1.1464e-01, 3.3892e-01, 2.9062e-02, 1.1033e-01, 1.9180e-02, 6.7127e-02,\n",
      "        1.0000e+00, 1.0000e+00, 1.0754e-01, 4.0798e-01, 1.2409e-02, 1.0657e-01,\n",
      "        7.2134e-03, 5.7047e-02])\n",
      "tensor([1.0000e+00, 1.0000e+00, 6.1312e-01, 7.3053e-01, 3.4059e-02, 1.6757e-01,\n",
      "        1.8575e-02, 9.0719e-02, 1.0000e+00, 1.0000e+00, 4.8852e-03, 1.1927e-03,\n",
      "        3.1927e-04, 5.7586e-04, 2.4668e-04, 4.2715e-04, 1.0000e+00, 1.0000e+00,\n",
      "        4.1938e-03, 1.8174e-03])\n",
      "tensor([1.3211e-04, 4.7093e-04, 5.2111e-05, 3.2630e-04, 1.0000e+00, 1.0000e+00,\n",
      "        1.5991e-02, 5.8925e-03, 2.4455e-04, 7.8572e-04, 9.6206e-05, 5.7807e-04,\n",
      "        1.0000e+00, 1.0000e+00, 9.9364e-01, 9.9987e-01, 5.0090e-01, 9.7266e-01,\n",
      "        5.0093e-01, 9.7855e-01])\n",
      "tensor([1.0000, 1.0000, 0.9890, 0.9978, 0.0589, 0.9178, 0.0662, 0.9407, 1.0000,\n",
      "        1.0000, 0.9528, 0.9994, 0.1476, 0.9408, 0.1560, 0.9593, 1.0000, 1.0000,\n",
      "        0.9633, 0.9907])\n",
      "tensor([0.9883, 0.9986, 0.9995, 1.0000, 1.0000, 1.0000, 0.9980, 0.9137, 0.8988,\n",
      "        0.9754, 0.9928, 0.9953, 1.0000, 1.0000, 0.9947, 0.9788, 0.7955, 0.9639,\n",
      "        0.8521, 0.9851])\n",
      "tensor([1.0000e+00, 1.0000e+00, 4.8089e-01, 9.9896e-01, 8.0892e-06, 1.1083e-04,\n",
      "        1.3735e-05, 3.6238e-04, 1.0000e+00, 1.0000e+00, 8.0198e-01, 9.9953e-01,\n",
      "        1.7286e-06, 8.6836e-05, 2.1706e-06, 1.2101e-04, 1.0000e+00, 1.0000e+00,\n",
      "        5.8744e-01, 9.9890e-01])\n",
      "tensor([1.8605e-06, 1.8013e-04, 1.5771e-06, 3.0314e-04, 1.0000e+00, 1.0000e+00,\n",
      "        4.2763e-03, 5.2882e-02, 8.9927e-04, 2.1139e-02, 8.9312e-03, 2.3789e-01,\n",
      "        1.0000e+00, 1.0000e+00, 7.2009e-03, 3.2498e-01, 1.8716e-04, 2.0973e-03,\n",
      "        1.1162e-03, 1.6261e-02])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.4956e-01, 2.5588e-01, 6.4523e-05, 3.4813e-03,\n",
      "        1.4485e-04, 1.1543e-02, 1.0000e+00, 1.0000e+00, 5.2452e-07, 2.3359e-06,\n",
      "        6.8834e-08, 4.6831e-08, 1.5850e-08, 1.1890e-08, 1.0000e+00, 1.0000e+00,\n",
      "        7.3339e-07, 1.1098e-05])\n",
      "tensor([7.4289e-08, 4.4137e-08, 1.7511e-08, 1.9234e-08, 1.0000e+00, 1.0000e+00,\n",
      "        1.1195e-05, 7.7332e-05, 8.4217e-08, 8.6415e-08, 1.9374e-08, 3.3351e-08,\n",
      "        1.0000e+00, 9.6236e-01, 2.1795e-08, 3.4268e-09, 2.6530e-09, 8.8214e-10,\n",
      "        7.7886e-10, 3.3763e-10])\n",
      "tensor([1.0000e+00, 8.4540e-01, 4.6264e-08, 4.5095e-09, 2.4391e-09, 8.6114e-10,\n",
      "        6.9883e-10, 3.3379e-10, 9.9998e-01, 9.3076e-01, 9.7144e-08, 1.1558e-08,\n",
      "        2.3762e-09, 9.1288e-10, 7.9362e-10, 3.2472e-10, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00])\n",
      "tensor([0.0210, 0.0308, 0.0036, 0.0128, 1.0000, 1.0000, 1.0000, 0.9999, 0.0175,\n",
      "        0.0563, 0.0039, 0.0246, 1.0000, 1.0000, 0.9952, 0.9995, 0.0720, 0.1285,\n",
      "        0.0202, 0.0518])\n",
      "tensor([1.0000e+00, 1.0000e+00, 3.2372e-02, 4.2399e-03, 4.2144e-04, 2.0738e-04,\n",
      "        2.3384e-04, 2.5538e-04, 1.0000e+00, 1.0000e+00, 7.4843e-03, 5.3314e-03,\n",
      "        3.5410e-04, 2.1995e-04, 1.4324e-04, 3.1123e-04, 1.0000e+00, 1.0000e+00,\n",
      "        9.4007e-03, 2.1720e-02])\n",
      "tensor([4.1031e-04, 6.0145e-04, 2.7841e-04, 6.0343e-04, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.9997e-01, 9.9999e-01, 9.9940e-01, 9.9967e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9964e-01, 9.9879e-01,\n",
      "        9.8703e-01, 9.9245e-01])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.8730, 0.9992, 0.7232, 0.9939, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n",
      "tensor([1.0000, 0.9994, 1.0000, 0.9957, 1.0000, 1.0000, 1.0000, 1.0000, 0.9994,\n",
      "        0.9955, 0.9961, 0.9938])\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        accuracy            0.9513888955116272\n",
      "        test_loss          0.015096260234713554\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.015096260234713554, 'accuracy': 0.9513888955116272}]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no good estimation of model, just testing\n",
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ea1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
