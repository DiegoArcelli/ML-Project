{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37f696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.inizalizers import RandomNormal, RandomUniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras import layers\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60634f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monks(path):\n",
    "    train = pd.read_csv(f\"{path}.train\", header=None, sep=\" \")\n",
    "    test = pd.read_csv(f\"{path}.test\", header=None, sep=\" \")\n",
    "    \n",
    "    train.drop(0, axis=1, inplace=True)\n",
    "    test.drop(0, axis=1, inplace=True)\n",
    "    train.drop(8, axis=1, inplace=True)\n",
    "    test.drop(8, axis=1, inplace=True)\n",
    "    \n",
    "    y_train = train.iloc[:, 0].to_numpy().astype(np.float64)\n",
    "    x_train = train.iloc[:, 1:].to_numpy().astype(np.float64)\n",
    "    y_test = test.iloc[:, 0].to_numpy().astype(np.float64)\n",
    "    x_test = test.iloc[:, 1:].to_numpy().astype(np.float64)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    \n",
    "\n",
    "def load_cup():\n",
    "    train = pd.read_csv(\"../data/ML-CUP22-TR.csv\", header=None, sep=\",\")\n",
    "    test = pd.read_csv(\"../data/ML-CUP22-TS.csv\", header=None, sep=\",\")\n",
    "    train.drop(0, axis=1, inplace=True)\n",
    "    test.drop(0, axis=1, inplace=True)\n",
    "    train.head()\n",
    "    y_train = train.iloc[:, :2].to_numpy().astype(np.float64)\n",
    "    x_train = train.iloc[:, 2:].to_numpy().astype(np.float64)\n",
    "    x_test = test.to_numpy().astype(np.float64)\n",
    "    return x_train, y_train, x_test, None\n",
    "    \n",
    "def load_dataset(dataset):\n",
    "    assert dataset in [\"monks1\", \"monks2\", \"monks3\", \"cup\"]\n",
    "    \n",
    "    if dataset == \"monks1\":\n",
    "        return load_monks(\"./../data/monks-1\")\n",
    "    elif dataset == \"monks2\":\n",
    "        return load_monks(\"./../data/monks-2\")\n",
    "    elif dataset == \"monks3\":\n",
    "        return load_monks(\"./../data/monks-3\")\n",
    "    else:\n",
    "        return load_cup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de75223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 6) (124,)\n",
      "(432, 6) (432,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_dataset(\"monks1\")\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0a538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a4b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/576 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                           | 1/576 [00:00<09:27,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.3684210479259491\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                          | 2/576 [00:09<49:28,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 0.5263158082962036\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏                                        | 3/576 [00:20<1:15:33,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 0.6842105388641357\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                          | 4/576 [00:21<49:05,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.5789473652839661\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                        | 5/576 [00:34<1:18:20,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 0.4736842215061188\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                        | 6/576 [00:50<1:43:38, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427 0.6842105388641357\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                        | 7/576 [00:58<1:34:03,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 0.5789473652839661\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.01, 'activations_1': 'relu', 'units_1': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                        | 8/576 [01:03<1:16:48,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.6315789222717285\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'momentum': 0.1, 'regularizer': 0.1, 'activations_1': 'relu', 'units_1': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                        | 8/576 [01:08<1:21:11,  8.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 171\u001b[0m\n\u001b[1;32m    166\u001b[0m     configurations \u001b[38;5;241m=\u001b[39m get_configurations(params)\n\u001b[1;32m    167\u001b[0m     model_selection(configurations, x_train, y_train)        \n\u001b[0;32m--> 171\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [11], line 167\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(params, x_train, y_train, validation)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrid_search\u001b[39m(params, x_train, y_train, validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    166\u001b[0m     configurations \u001b[38;5;241m=\u001b[39m get_configurations(params)\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mmodel_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [11], line 160\u001b[0m, in \u001b[0;36mmodel_selection\u001b[0;34m(configurations, x_train, y_train)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[1;32m    159\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(config)\n\u001b[0;32m--> 160\u001b[0m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [11], line 143\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model, x_train, y_train, max_epochs, batch_size, val_split)\u001b[0m\n\u001b[1;32m    132\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m    133\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    141\u001b[0m x_train, x_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(x_train, y_train, test_size\u001b[38;5;241m=\u001b[39mval_split, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 143\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    147\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Universita/Magistrale/FirstYear/ML/ML-Project/env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Universita/Magistrale/FirstYear/ML/ML-Project/env/lib/python3.10/site-packages/keras/engine/training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[0;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m }\n\u001b[1;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Desktop/Universita/Magistrale/FirstYear/ML/ML-Project/env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1],\n",
    "    \"batch_size\": [16 , 64],\n",
    "    \"momentum\": [0.1, 0.5, 0.9],\n",
    "    \"regularizer\": [0.01, 0.1, 1],\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"activations\": [\"relu\"],\n",
    "            \"units\": [1,2,3,4,5,6,7,8],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "k_fold_val = {\n",
    "    \"type\": \"k-fold\",\n",
    "    \"n_folds\": [2, 3, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "hold_out_val = {\n",
    "    \"type\": \"hold-out\",\n",
    "    \"val_split\": 0.2\n",
    "}\n",
    "\n",
    "\n",
    "def merge_dicts(dicts):\n",
    "    merged = {}\n",
    "    for d in dicts:\n",
    "        merged = {**merged, **d}\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def get_params_configurations(params):\n",
    "    \n",
    "    keys = list(params.keys())\n",
    "    keys.remove(\"layers\")\n",
    "    sorted_keys = sorted(keys)\n",
    "    arguments = []\n",
    "    for key in sorted_keys:\n",
    "        arguments.append(params[key])\n",
    "    \n",
    "    arguments = tuple(arguments)\n",
    "    all_params = list(itertools.product(*arguments))\n",
    "    \n",
    "    configurations = []\n",
    "    \n",
    "    for conf in all_params:\n",
    "        \n",
    "        dict_conf = {}\n",
    "        \n",
    "        for i in range(len(sorted_keys)):\n",
    "            dict_conf[sorted_keys[i]] = conf[i]\n",
    "        \n",
    "        configurations.append(dict_conf)\n",
    "        \n",
    "    return configurations\n",
    "\n",
    "\n",
    "\n",
    "def get_layers_configurations(params, configurations):\n",
    "    layers = params[\"layers\"]\n",
    "    layers_params_confs = []\n",
    "    \n",
    "    for n_layer in range(len(layers)):\n",
    "        layers_params_confs.append([]) \n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        activations = layer[\"activations\"]\n",
    "        units = layer[\"units\"]\n",
    "        layer_confs = list(itertools.product(activations, units))\n",
    "        for conf in layer_confs:\n",
    "            conf_dict = {\n",
    "                f\"activations_{i+1}\": conf[0],\n",
    "                f\"units_{i+1}\": conf[1]\n",
    "            }\n",
    "            layers_params_confs[i].append(conf_dict)\n",
    "        \n",
    "    layers_confs = []\n",
    "    for i in range(len(layers_params_confs)):\n",
    "        confs = layers_params_confs[:i+1]\n",
    "        confs = tuple(confs)\n",
    "        confs = list(itertools.product(*confs))\n",
    "        for conf in confs:\n",
    "            layers_confs.append(merge_dicts(conf))\n",
    "                \n",
    "    return layers_confs\n",
    "\n",
    "\n",
    "\n",
    "def get_configurations(params):\n",
    "    configurations = get_params_configurations(params)\n",
    "    layers_confs = get_layers_configurations(params, configurations)\n",
    "    configurations = list(itertools.product(configurations, layers_confs))\n",
    "    configurations_merged = []\n",
    "    \n",
    "    for conf in configurations:\n",
    "        configurations_merged.append(merge_dicts(conf))\n",
    "        \n",
    "    \n",
    "    return configurations_merged\n",
    "    \n",
    "    \n",
    "def get_model(config):    \n",
    "    lr = config[\"learning_rate\"]\n",
    "    reg = config[\"regularizer\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    \n",
    "    n_layers = 0\n",
    "    for key in config.keys():\n",
    "        if key.startswith(\"units_\"):\n",
    "            n_layers += 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(6, input_dim=6, activation=\"relu\", kernel_regularizer=l2(reg), bias_regularizer=l2(reg)))\n",
    "    \n",
    "    for l in range(1,n_layers+1):\n",
    "        activation = config[f\"activations_{l}\"]\n",
    "        n_units = config[f\"units_{l}\"]\n",
    "        model.add(Dense(n_units, activation=activation, kernel_regularizer=l2(reg), bias_regularizer=l2(reg)))\n",
    "        \n",
    "    model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(reg), bias_regularizer=l2(reg)))\n",
    "    \n",
    "    optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def fit_model(model, x_train, y_train, max_epochs, batch_size, val_split):\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_split, shuffle=True)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=max_epochs, batch_size=batch_size,\n",
    "                        verbose=0, validation_data=(x_val, y_val), callbacks=[early_stop])\n",
    "    \n",
    "    train_loss = history.history[\"loss\"]\n",
    "    train_acc = history.history[\"accuracy\"]\n",
    "    \n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    \n",
    "    print(len(train_loss), val_acc[-1])\n",
    "    \n",
    "    \n",
    "def model_selection(configurations, x_train, y_train):\n",
    "    with tqdm(total=len(configurations)) as pbar:\n",
    "        for config in configurations:\n",
    "            print(config)\n",
    "            model = get_model(config)\n",
    "            fit_model(model, x_train, y_train, 500, config[\"batch_size\"], 0.15)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    \n",
    "\n",
    "def grid_search(params, x_train, y_train, validation=None):\n",
    "    configurations = get_configurations(params)\n",
    "    model_selection(configurations, x_train, y_train)        \n",
    "        \n",
    "        \n",
    "\n",
    "grid_search(params, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a043c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=6, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = SGD(learning_rate=0.1, momentum=0.9)\n",
    "    model.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4063a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2291 - accuracy: 0.6415 - val_loss: 0.1571 - val_accuracy: 0.8000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2019 - accuracy: 0.6981 - val_loss: 0.1886 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.7547 - val_loss: 0.2832 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1509 - accuracy: 0.8491 - val_loss: 0.1432 - val_accuracy: 0.8000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2094 - accuracy: 0.6792 - val_loss: 0.1227 - val_accuracy: 0.9000\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1523 - accuracy: 0.7925 - val_loss: 0.1926 - val_accuracy: 0.6000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.8302 - val_loss: 0.1295 - val_accuracy: 0.8000\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.7925 - val_loss: 0.1200 - val_accuracy: 0.8000\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.8113 - val_loss: 0.2469 - val_accuracy: 0.6000\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1633 - accuracy: 0.7736 - val_loss: 0.2604 - val_accuracy: 0.6000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.8113 - val_loss: 0.1301 - val_accuracy: 0.7000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1421 - accuracy: 0.8113 - val_loss: 0.1861 - val_accuracy: 0.6000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1292 - accuracy: 0.8302 - val_loss: 0.1511 - val_accuracy: 0.6000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 0.8113 - val_loss: 0.1420 - val_accuracy: 0.7000\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.8113 - val_loss: 0.1986 - val_accuracy: 0.7000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.8491 - val_loss: 0.2583 - val_accuracy: 0.6000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1340 - accuracy: 0.8679 - val_loss: 0.1553 - val_accuracy: 0.7000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1270 - accuracy: 0.8491 - val_loss: 0.1929 - val_accuracy: 0.7000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1250 - accuracy: 0.8302 - val_loss: 0.1905 - val_accuracy: 0.7000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1227 - accuracy: 0.8302 - val_loss: 0.1271 - val_accuracy: 0.7000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1214 - accuracy: 0.8113 - val_loss: 0.1772 - val_accuracy: 0.7000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1202 - accuracy: 0.8679 - val_loss: 0.2201 - val_accuracy: 0.7000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1201 - accuracy: 0.8679 - val_loss: 0.2138 - val_accuracy: 0.7000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.9057 - val_loss: 0.2658 - val_accuracy: 0.6000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1172 - accuracy: 0.8679 - val_loss: 0.1480 - val_accuracy: 0.7000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1518 - accuracy: 0.7736 - val_loss: 0.1049 - val_accuracy: 0.9000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1312 - accuracy: 0.8113 - val_loss: 0.2442 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1212 - accuracy: 0.8491 - val_loss: 0.2583 - val_accuracy: 0.6000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1285 - accuracy: 0.8491 - val_loss: 0.2142 - val_accuracy: 0.7000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1109 - accuracy: 0.8679 - val_loss: 0.1767 - val_accuracy: 0.7000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 0.8491 - val_loss: 0.1915 - val_accuracy: 0.7000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1065 - accuracy: 0.9057 - val_loss: 0.2119 - val_accuracy: 0.7000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1105 - accuracy: 0.8679 - val_loss: 0.2167 - val_accuracy: 0.7000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.8491 - val_loss: 0.1554 - val_accuracy: 0.8000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1169 - accuracy: 0.8679 - val_loss: 0.2312 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1077 - accuracy: 0.9057 - val_loss: 0.1248 - val_accuracy: 0.8000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1171 - accuracy: 0.8491 - val_loss: 0.1254 - val_accuracy: 0.8000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1154 - accuracy: 0.8491 - val_loss: 0.1922 - val_accuracy: 0.7000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1173 - accuracy: 0.8679 - val_loss: 0.2348 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 0.8868 - val_loss: 0.1594 - val_accuracy: 0.8000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.8679 - val_loss: 0.1491 - val_accuracy: 0.8000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1066 - accuracy: 0.8679 - val_loss: 0.2159 - val_accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1040 - accuracy: 0.8868 - val_loss: 0.1768 - val_accuracy: 0.7000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1043 - accuracy: 0.8679 - val_loss: 0.1863 - val_accuracy: 0.7000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1014 - accuracy: 0.9057 - val_loss: 0.2196 - val_accuracy: 0.7000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1056 - accuracy: 0.8868 - val_loss: 0.2133 - val_accuracy: 0.7000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1022 - accuracy: 0.8868 - val_loss: 0.2192 - val_accuracy: 0.7000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1024 - accuracy: 0.9057 - val_loss: 0.2255 - val_accuracy: 0.7000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 0.8868 - val_loss: 0.2399 - val_accuracy: 0.7000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9057 - val_loss: 0.2088 - val_accuracy: 0.7000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9057 - val_loss: 0.1975 - val_accuracy: 0.7000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0990 - accuracy: 0.9057 - val_loss: 0.2173 - val_accuracy: 0.7000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9057 - val_loss: 0.2389 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0974 - accuracy: 0.9057 - val_loss: 0.2331 - val_accuracy: 0.7000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0973 - accuracy: 0.9057 - val_loss: 0.2276 - val_accuracy: 0.7000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0948 - accuracy: 0.9057 - val_loss: 0.2081 - val_accuracy: 0.7000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0976 - accuracy: 0.9057 - val_loss: 0.2149 - val_accuracy: 0.7000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9057 - val_loss: 0.2368 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.9057 - val_loss: 0.2824 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9057 - val_loss: 0.2068 - val_accuracy: 0.8000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.8868 - val_loss: 0.2033 - val_accuracy: 0.8000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0974 - accuracy: 0.9057 - val_loss: 0.2342 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1032 - accuracy: 0.8868 - val_loss: 0.2343 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0947 - accuracy: 0.9057 - val_loss: 0.1786 - val_accuracy: 0.8000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0885 - accuracy: 0.9057 - val_loss: 0.2373 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0973 - accuracy: 0.8868 - val_loss: 0.2172 - val_accuracy: 0.7000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9057 - val_loss: 0.1660 - val_accuracy: 0.8000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.9057 - val_loss: 0.2128 - val_accuracy: 0.7000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0879 - accuracy: 0.8868 - val_loss: 0.1849 - val_accuracy: 0.8000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.8868 - val_loss: 0.1498 - val_accuracy: 0.8000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0873 - accuracy: 0.9057 - val_loss: 0.2058 - val_accuracy: 0.7000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0829 - accuracy: 0.9057 - val_loss: 0.1982 - val_accuracy: 0.8000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9057 - val_loss: 0.1864 - val_accuracy: 0.8000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9057 - val_loss: 0.2087 - val_accuracy: 0.7000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0804 - accuracy: 0.9057 - val_loss: 0.1839 - val_accuracy: 0.8000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0803 - accuracy: 0.9057 - val_loss: 0.1844 - val_accuracy: 0.7000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0818 - accuracy: 0.9057 - val_loss: 0.2081 - val_accuracy: 0.7000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9057 - val_loss: 0.2038 - val_accuracy: 0.7000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 0.9057 - val_loss: 0.1598 - val_accuracy: 0.8000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0805 - accuracy: 0.9057 - val_loss: 0.1904 - val_accuracy: 0.7000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0748 - accuracy: 0.9057 - val_loss: 0.1841 - val_accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 0.9057 - val_loss: 0.1655 - val_accuracy: 0.9000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.8868 - val_loss: 0.1836 - val_accuracy: 0.8000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0965 - accuracy: 0.8868 - val_loss: 0.2143 - val_accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9057 - val_loss: 0.1307 - val_accuracy: 0.9000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0784 - accuracy: 0.9057 - val_loss: 0.2026 - val_accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0736 - accuracy: 0.9057 - val_loss: 0.2035 - val_accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0747 - accuracy: 0.9057 - val_loss: 0.1952 - val_accuracy: 0.8000\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0742 - accuracy: 0.9057 - val_loss: 0.2003 - val_accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0744 - accuracy: 0.9057 - val_loss: 0.1902 - val_accuracy: 0.8000\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0753 - accuracy: 0.9057 - val_loss: 0.1455 - val_accuracy: 0.9000\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.9057 - val_loss: 0.2045 - val_accuracy: 0.7000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.9057 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.9057 - val_loss: 0.1572 - val_accuracy: 0.9000\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0776 - accuracy: 0.9057 - val_loss: 0.2542 - val_accuracy: 0.7000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0848 - accuracy: 0.9057 - val_loss: 0.1545 - val_accuracy: 0.8000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1157 - accuracy: 0.8302 - val_loss: 0.2017 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1072 - accuracy: 0.8302 - val_loss: 0.2406 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1379 - accuracy: 0.7736 - val_loss: 0.1473 - val_accuracy: 0.8000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1180 - accuracy: 0.8113 - val_loss: 0.1844 - val_accuracy: 0.8000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1542 - accuracy: 0.8113 - val_loss: 0.1385 - val_accuracy: 0.8000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1159 - accuracy: 0.8491 - val_loss: 0.2078 - val_accuracy: 0.8000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1203 - accuracy: 0.8491 - val_loss: 0.2480 - val_accuracy: 0.7000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0878 - accuracy: 0.8868 - val_loss: 0.0858 - val_accuracy: 0.9000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1127 - accuracy: 0.8302 - val_loss: 0.0780 - val_accuracy: 0.9000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0997 - accuracy: 0.8491 - val_loss: 0.2188 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1106 - accuracy: 0.8491 - val_loss: 0.2499 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9057 - val_loss: 0.1188 - val_accuracy: 0.9000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0861 - accuracy: 0.8679 - val_loss: 0.1190 - val_accuracy: 0.9000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.8868 - val_loss: 0.1667 - val_accuracy: 0.8000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0659 - accuracy: 0.9057 - val_loss: 0.1728 - val_accuracy: 0.8000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0650 - accuracy: 0.9057 - val_loss: 0.1681 - val_accuracy: 0.8000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0647 - accuracy: 0.9057 - val_loss: 0.1605 - val_accuracy: 0.8000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0599 - accuracy: 0.9057 - val_loss: 0.1586 - val_accuracy: 0.9000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0587 - accuracy: 0.9057 - val_loss: 0.1679 - val_accuracy: 0.8000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9245 - val_loss: 0.1692 - val_accuracy: 0.8000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 0.9245 - val_loss: 0.1735 - val_accuracy: 0.7000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9434 - val_loss: 0.1701 - val_accuracy: 0.7000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0566 - accuracy: 0.9245 - val_loss: 0.1635 - val_accuracy: 0.8000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9245 - val_loss: 0.1482 - val_accuracy: 0.9000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 0.9623 - val_loss: 0.1758 - val_accuracy: 0.8000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9057 - val_loss: 0.1953 - val_accuracy: 0.8000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 0.9434 - val_loss: 0.1464 - val_accuracy: 0.8000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0553 - accuracy: 0.9623 - val_loss: 0.1614 - val_accuracy: 0.8000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 0.1687 - val_accuracy: 0.8000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.1698 - val_accuracy: 0.8000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0455 - accuracy: 0.9623 - val_loss: 0.1481 - val_accuracy: 0.9000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0419 - accuracy: 0.9434 - val_loss: 0.1445 - val_accuracy: 0.9000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9245 - val_loss: 0.1458 - val_accuracy: 0.9000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0409 - accuracy: 0.9434 - val_loss: 0.1551 - val_accuracy: 0.8000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.8000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.9623 - val_loss: 0.2096 - val_accuracy: 0.8000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0486 - accuracy: 0.9245 - val_loss: 0.1321 - val_accuracy: 0.9000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0470 - accuracy: 0.9623 - val_loss: 0.1381 - val_accuracy: 0.9000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 0.9057 - val_loss: 0.1419 - val_accuracy: 0.9000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.1577 - val_accuracy: 0.7000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9434 - val_loss: 0.1332 - val_accuracy: 0.9000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0321 - accuracy: 0.9811 - val_loss: 0.1529 - val_accuracy: 0.8000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.8000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.8000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9811 - val_loss: 0.1497 - val_accuracy: 0.9000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0262 - accuracy: 0.9811 - val_loss: 0.1504 - val_accuracy: 0.8000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9000\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9000\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9000\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9000\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9000\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9000\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9000\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9000\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9000\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9000\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9000\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9000\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9000\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9000\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9000\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9000\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9000\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9000\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9000\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9000\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9000\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9000\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9000\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9000\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9000\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9000\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9000\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9000\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9000\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9000\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9000\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3134674fa0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=100,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, shuffle=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=300, batch_size=16, callbacks=[early_stop], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "258b6a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.22917773],\n",
       "       [0.2229525 ],\n",
       "       [0.26184192],\n",
       "       [0.25502297],\n",
       "       [0.2973657 ],\n",
       "       [0.28998503],\n",
       "       [0.33551827],\n",
       "       [0.32763222],\n",
       "       [0.21924704],\n",
       "       [0.21321695],\n",
       "       [0.25095665],\n",
       "       [0.24432737],\n",
       "       [0.28557494],\n",
       "       [0.27837104],\n",
       "       [0.32291   ],\n",
       "       [0.31517974],\n",
       "       [0.20962965],\n",
       "       [0.20379503],\n",
       "       [0.24037653],\n",
       "       [0.23393947],\n",
       "       [0.27406937],\n",
       "       [0.26704723],\n",
       "       [0.3105541 ],\n",
       "       [0.30298725],\n",
       "       [0.23476976],\n",
       "       [0.22843766],\n",
       "       [0.2679539 ],\n",
       "       [0.2610321 ],\n",
       "       [0.3039654 ],\n",
       "       [0.2964901 ],\n",
       "       [0.34255195],\n",
       "       [0.33458385],\n",
       "       [0.2246674 ],\n",
       "       [0.21852994],\n",
       "       [0.25690302],\n",
       "       [0.2501691 ],\n",
       "       [0.29202175],\n",
       "       [0.28472003],\n",
       "       [0.32981056],\n",
       "       [0.32199368],\n",
       "       [0.21487768],\n",
       "       [0.2089356 ],\n",
       "       [0.24615462],\n",
       "       [0.23961158],\n",
       "       [0.28035837],\n",
       "       [0.2732357 ],\n",
       "       [0.31731436],\n",
       "       [0.3096568 ],\n",
       "       [0.7019453 ],\n",
       "       [0.29238048],\n",
       "       [0.14161271],\n",
       "       [0.33019403],\n",
       "       [0.10577689],\n",
       "       [0.3703386 ],\n",
       "       [0.07818355],\n",
       "       [0.36801007],\n",
       "       [0.29394174],\n",
       "       [0.28070843],\n",
       "       [0.15892167],\n",
       "       [0.31769016],\n",
       "       [0.1193146 ],\n",
       "       [0.35712507],\n",
       "       [0.08853941],\n",
       "       [0.39859533],\n",
       "       [0.23184484],\n",
       "       [0.26932502],\n",
       "       [0.17790782],\n",
       "       [0.3054439 ],\n",
       "       [0.13432464],\n",
       "       [0.3441253 ],\n",
       "       [0.10011799],\n",
       "       [0.38499007],\n",
       "       [0.42860308],\n",
       "       [0.29891664],\n",
       "       [0.14804123],\n",
       "       [0.33717275],\n",
       "       [0.11078862],\n",
       "       [0.3776873 ],\n",
       "       [0.08200778],\n",
       "       [0.38016427],\n",
       "       [0.2172614 ],\n",
       "       [0.28708956],\n",
       "       [0.16598402],\n",
       "       [0.32453266],\n",
       "       [0.12487814],\n",
       "       [0.3643633 ],\n",
       "       [0.09281919],\n",
       "       [0.4061431 ],\n",
       "       [0.2412184 ],\n",
       "       [0.2755465 ],\n",
       "       [0.18562768],\n",
       "       [0.3121433 ],\n",
       "       [0.14047645],\n",
       "       [0.3512441 ],\n",
       "       [0.10489303],\n",
       "       [0.39244837],\n",
       "       [0.96391034],\n",
       "       [0.926657  ],\n",
       "       [0.57777506],\n",
       "       [0.39295495],\n",
       "       [0.06551613],\n",
       "       [0.10625605],\n",
       "       [0.01226391],\n",
       "       [0.0785487 ],\n",
       "       [0.8252161 ],\n",
       "       [0.69073164],\n",
       "       [0.19477937],\n",
       "       [0.15959868],\n",
       "       [0.01944737],\n",
       "       [0.11984688],\n",
       "       [0.01402115],\n",
       "       [0.08894829],\n",
       "       [0.4549228 ],\n",
       "       [0.28305593],\n",
       "       [0.04100689],\n",
       "       [0.17864846],\n",
       "       [0.02221073],\n",
       "       [0.13491358],\n",
       "       [0.01602607],\n",
       "       [0.1005744 ],\n",
       "       [0.8948115 ],\n",
       "       [0.80096   ],\n",
       "       [0.30354252],\n",
       "       [0.17093161],\n",
       "       [0.02184216],\n",
       "       [0.11128765],\n",
       "       [0.01290894],\n",
       "       [0.08238919],\n",
       "       [0.60059965],\n",
       "       [0.41566622],\n",
       "       [0.07153272],\n",
       "       [0.16668512],\n",
       "       [0.02046238],\n",
       "       [0.12543175],\n",
       "       [0.01475722],\n",
       "       [0.0932458 ],\n",
       "       [0.2099991 ],\n",
       "       [0.24214496],\n",
       "       [0.032291  ],\n",
       "       [0.18639316],\n",
       "       [0.02336654],\n",
       "       [0.14108798],\n",
       "       [0.01686558],\n",
       "       [0.10536865],\n",
       "       [0.7845363 ],\n",
       "       [0.20056342],\n",
       "       [0.23627293],\n",
       "       [0.22150746],\n",
       "       [0.26022923],\n",
       "       [0.25343788],\n",
       "       [0.29562184],\n",
       "       [0.2882667 ],\n",
       "       [0.35978895],\n",
       "       [0.1986939 ],\n",
       "       [0.2178193 ],\n",
       "       [0.21181782],\n",
       "       [0.24938837],\n",
       "       [0.24278708],\n",
       "       [0.2838723 ],\n",
       "       [0.2766947 ],\n",
       "       [0.1986939 ],\n",
       "       [0.1986939 ],\n",
       "       [0.20824784],\n",
       "       [0.20244181],\n",
       "       [0.23885329],\n",
       "       [0.2324445 ],\n",
       "       [0.27240917],\n",
       "       [0.26541397],\n",
       "       [0.531025  ],\n",
       "       [0.1986939 ],\n",
       "       [0.2332711 ],\n",
       "       [0.22696745],\n",
       "       [0.26631716],\n",
       "       [0.25942266],\n",
       "       [0.3021995 ],\n",
       "       [0.29474923],\n",
       "       [0.1986939 ],\n",
       "       [0.1986939 ],\n",
       "       [0.22321442],\n",
       "       [0.21710558],\n",
       "       [0.2553102 ],\n",
       "       [0.24860409],\n",
       "       [0.2902963 ],\n",
       "       [0.28302047],\n",
       "       [0.1986939 ],\n",
       "       [0.1986939 ],\n",
       "       [0.2134706 ],\n",
       "       [0.20755714],\n",
       "       [0.24460651],\n",
       "       [0.23809163],\n",
       "       [0.27867472],\n",
       "       [0.2715787 ],\n",
       "       [0.99753594],\n",
       "       [0.96418184],\n",
       "       [0.97184163],\n",
       "       [0.69650036],\n",
       "       [0.74634457],\n",
       "       [0.32834765],\n",
       "       [0.37670854],\n",
       "       [0.36839116],\n",
       "       [0.9833377 ],\n",
       "       [0.7969185 ],\n",
       "       [0.83419675],\n",
       "       [0.27902347],\n",
       "       [0.32362002],\n",
       "       [0.31588072],\n",
       "       [0.3633989 ],\n",
       "       [0.3552079 ],\n",
       "       [0.89586717],\n",
       "       [0.36388642],\n",
       "       [0.42311162],\n",
       "       [0.26768297],\n",
       "       [0.31124943],\n",
       "       [0.30367318],\n",
       "       [0.35029528],\n",
       "       [0.3422408 ],\n",
       "       [0.99214584],\n",
       "       [0.8936112 ],\n",
       "       [0.9150327 ],\n",
       "       [0.41727567],\n",
       "       [0.47865182],\n",
       "       [0.33530682],\n",
       "       [0.3841066 ],\n",
       "       [0.3757243 ],\n",
       "       [0.9484927 ],\n",
       "       [0.55045027],\n",
       "       [0.6108799 ],\n",
       "       [0.2853815 ],\n",
       "       [0.33052835],\n",
       "       [0.32270265],\n",
       "       [0.37069103],\n",
       "       [0.36242923],\n",
       "       [0.7285878 ],\n",
       "       [0.24020343],\n",
       "       [0.28101367],\n",
       "       [0.27388072],\n",
       "       [0.31801784],\n",
       "       [0.31035104],\n",
       "       [0.35747206],\n",
       "       [0.34934136],\n",
       "       [0.99996465],\n",
       "       [0.9996671 ],\n",
       "       [0.9993104 ],\n",
       "       [0.99610925],\n",
       "       [0.98670995],\n",
       "       [0.9561911 ],\n",
       "       [0.79183424],\n",
       "       [0.64278287],\n",
       "       [0.9998    ],\n",
       "       [0.99772096],\n",
       "       [0.9961114 ],\n",
       "       [0.9739052 ],\n",
       "       [0.9292001 ],\n",
       "       [0.7608675 ],\n",
       "       [0.40206268],\n",
       "       [0.44237405],\n",
       "       [0.99886984],\n",
       "       [0.9845722 ],\n",
       "       [0.97839344],\n",
       "       [0.84473616],\n",
       "       [0.6987961 ],\n",
       "       [0.38575888],\n",
       "       [0.13434148],\n",
       "       [0.42833874],\n",
       "       [0.999889  ],\n",
       "       [0.998934  ],\n",
       "       [0.997838  ],\n",
       "       [0.987637  ],\n",
       "       [0.9594269 ],\n",
       "       [0.8719674 ],\n",
       "       [0.54782474],\n",
       "       [0.46106836],\n",
       "       [0.9993724 ],\n",
       "       [0.9927326 ],\n",
       "       [0.9878917 ],\n",
       "       [0.9209208 ],\n",
       "       [0.80695343],\n",
       "       [0.49819654],\n",
       "       [0.17638856],\n",
       "       [0.45013034],\n",
       "       [0.99646014],\n",
       "       [0.95218325],\n",
       "       [0.9351593 ],\n",
       "       [0.6293066 ],\n",
       "       [0.4249317 ],\n",
       "       [0.39322245],\n",
       "       [0.14049393],\n",
       "       [0.4360414 ],\n",
       "       [0.997535  ],\n",
       "       [0.96537715],\n",
       "       [0.9665733 ],\n",
       "       [0.6658168 ],\n",
       "       [0.7089972 ],\n",
       "       [0.22006914],\n",
       "       [0.25862303],\n",
       "       [0.25185928],\n",
       "       [0.98424166],\n",
       "       [0.81144464],\n",
       "       [0.81695044],\n",
       "       [0.23518604],\n",
       "       [0.26208463],\n",
       "       [0.21042539],\n",
       "       [0.24782664],\n",
       "       [0.24125339],\n",
       "       [0.90601504],\n",
       "       [0.39911437],\n",
       "       [0.40787446],\n",
       "       [0.1986939 ],\n",
       "       [0.20687272],\n",
       "       [0.20109533],\n",
       "       [0.23733668],\n",
       "       [0.23095624],\n",
       "       [0.99189425],\n",
       "       [0.89397115],\n",
       "       [0.89916676],\n",
       "       [0.37596294],\n",
       "       [0.4318918 ],\n",
       "       [0.22550392],\n",
       "       [0.26468682],\n",
       "       [0.25781965],\n",
       "       [0.9497152 ],\n",
       "       [0.5654673 ],\n",
       "       [0.57438815],\n",
       "       [0.1986939 ],\n",
       "       [0.22176819],\n",
       "       [0.2156879 ],\n",
       "       [0.25372392],\n",
       "       [0.24704565],\n",
       "       [0.74457365],\n",
       "       [0.1986939 ],\n",
       "       [0.1986939 ],\n",
       "       [0.1986939 ],\n",
       "       [0.21207024],\n",
       "       [0.20618543],\n",
       "       [0.24306503],\n",
       "       [0.23657835],\n",
       "       [0.99997324],\n",
       "       [0.999598  ],\n",
       "       [0.9996864 ],\n",
       "       [0.99530506],\n",
       "       [0.9963344 ],\n",
       "       [0.9475704 ],\n",
       "       [0.95863014],\n",
       "       [0.60642076],\n",
       "       [0.9998166 ],\n",
       "       [0.99724895],\n",
       "       [0.99785304],\n",
       "       [0.968656  ],\n",
       "       [0.9753834 ],\n",
       "       [0.7248701 ],\n",
       "       [0.7715831 ],\n",
       "       [0.3140768 ],\n",
       "       [0.9987433 ],\n",
       "       [0.9814278 ],\n",
       "       [0.98545516],\n",
       "       [0.8183497 ],\n",
       "       [0.8524225 ],\n",
       "       [0.27749297],\n",
       "       [0.32995048],\n",
       "       [0.3019082 ],\n",
       "       [0.9999143 ],\n",
       "       [0.99871284],\n",
       "       [0.99899584],\n",
       "       [0.9851078 ],\n",
       "       [0.9883466 ],\n",
       "       [0.84938353],\n",
       "       [0.8784995 ],\n",
       "       [0.33344606],\n",
       "       [0.9994125 ],\n",
       "       [0.99123657],\n",
       "       [0.9931518 ],\n",
       "       [0.9060414 ],\n",
       "       [0.92516965],\n",
       "       [0.4511794 ],\n",
       "       [0.51315093],\n",
       "       [0.32087806],\n",
       "       [0.9959836 ],\n",
       "       [0.94282097],\n",
       "       [0.95483476],\n",
       "       [0.5843243 ],\n",
       "       [0.6431524 ],\n",
       "       [0.2722212 ],\n",
       "       [0.31620738],\n",
       "       [0.3085645 ],\n",
       "       [0.99999976],\n",
       "       [0.9999964 ],\n",
       "       [0.9999972 ],\n",
       "       [0.99995774],\n",
       "       [0.99996704],\n",
       "       [0.99950427],\n",
       "       [0.99961334],\n",
       "       [0.994216  ],\n",
       "       [0.99999833],\n",
       "       [0.99997526],\n",
       "       [0.9999807 ],\n",
       "       [0.99971   ],\n",
       "       [0.9997738 ],\n",
       "       [0.9966093 ],\n",
       "       [0.99735343],\n",
       "       [0.96162367],\n",
       "       [0.99998873],\n",
       "       [0.9998304 ],\n",
       "       [0.99986774],\n",
       "       [0.9980143 ],\n",
       "       [0.9984505 ],\n",
       "       [0.97719353],\n",
       "       [0.9821223 ],\n",
       "       [0.785077  ],\n",
       "       [0.9999992 ],\n",
       "       [0.99998844],\n",
       "       [0.999991  ],\n",
       "       [0.9998645 ],\n",
       "       [0.9998943 ],\n",
       "       [0.998413  ],\n",
       "       [0.99876183],\n",
       "       [0.98169684],\n",
       "       [0.99999475],\n",
       "       [0.9999208 ],\n",
       "       [0.9999382 ],\n",
       "       [0.9990713 ],\n",
       "       [0.9992755 ],\n",
       "       [0.989214  ],\n",
       "       [0.99156743],\n",
       "       [0.88660544],\n",
       "       [0.9999639 ],\n",
       "       [0.9994567 ],\n",
       "       [0.9995762 ],\n",
       "       [0.9936638 ],\n",
       "       [0.9950512 ],\n",
       "       [0.9304087 ],\n",
       "       [0.944878  ],\n",
       "       [0.5326651 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "mlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
