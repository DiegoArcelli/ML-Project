{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_classes, y_counts = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=100, stratify=y, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((469, 30), (100, 30))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([175, 294], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_dev, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.ones_like(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.ones_like(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6268656716417911"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix()\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_pred, y_test, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_pred, y_test, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_curve\n",
    "fpr, tpr = roc_curve(y_test, y_test_pred, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Trasnformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_dev[:,0], alpha=.5, label='x0')\n",
    "plt.hist(X_dev[:,5], alpha=.5, label='x1')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_dev)\n",
    "X_dev_scaled = scaler.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATp0lEQVR4nO3df5Bd5X3f8fenSFhxjGsJLRS0ciVnkBNg8NReUUKcDEbVQFwPcqfxjGwIGpuOJi1xXKYxPxIsjcdmQqc0JB7bk9EYinBdGI1Dg+o2BEXYoZ2AYImxLX6r0IoFBa0lmhhiEUv+9o97abZi5b17f+xlj96vGebe85xz9vk+o53PHp577nNSVUiSmuXvDbsASVL/Ge6S1ECGuyQ1kOEuSQ1kuEtSAy0YdgEAS5curRUrVgy7DEmaVx555JHvV9XIdPveFOG+YsUKxsfHh12GJM0rSf73sfY5LSNJDWS4S1IDGe6S1EAzzrknuRX4ELC/qs6e0v5J4NeBw8B/raqr2+3XAVcAR4DfqKo/GUThkjQbP/rRj5iYmODQoUPDLmXWFi1axOjoKAsXLuz4nE4+UL0N+CJw++sNST4ArAPOqarXkpzSbj8TWA+cBZwO/GmSVVV1pOOKJGkAJiYmOOmkk1ixYgVJhl1Ox6qKAwcOMDExwcqVKzs+b8Zpmaq6Hzh4VPO/BG6sqtfax+xvt68D7qyq16rqOWAPcG7H1UjSgBw6dIiTTz55XgU7QBJOPvnkWf8fR7dz7quAX0yyK8mfJVndbl8GPD/luIl22xsk2ZhkPMn45ORkl2VIUufmW7C/rpu6uw33BcBi4Dzg08C2tHqfroJp1xSuqi1VNVZVYyMj096DL0nqUrdfYpoA7qrWYvAPJfkxsLTdvnzKcaPAi72VKEn9d/OOp/v6865au6qr87Zu3crnP/95AK6//no2bNjQl3q6Dfc/Ai4EvpVkFXAi8H1gO/CfkvwurQ9UzwAe6kOdmqLfv5Sz0e0vsKQ3OnjwIJ/97GcZHx8nCe973/u45JJLWLx4cc8/e8ZpmSR3AA8A704ykeQK4FbgXUl2A3cCG6rlMWAb8DhwD3Cld8pIEjz88MOcc845HDp0iFdffZWzzjqLL33pS6xdu5YlS5awePFi1q5dyz333NOX/ma8cq+qjx5j12XHOP4G4IZeipKkplm9ejWXXHIJ119/PT/84Q+57LLLWLhwIcuX/91M9ujoKC+88EJf+vMbqpI0RzZt2sSOHTsYHx/n6quvZrpnWPfrjh7DXZLmyMGDB3nllVf4wQ9+wKFDhxgdHeX55//u7vGJiQlOP/30vvRluEvSHNm4cSOf+9znuPTSS7nmmmu46KKLuPfee3n55Zd5+eWXuffee7nooov60tebYj33eeubvzOkjv/5kPqVmmOu7/y6/fbbWbBgAR/72Mc4cuQI559/Po8++iif+cxnWL269T3QTZs2sWTJkr70Z7hL0hy4/PLLufzyywE44YQT2LVr1//b94lPfKLv/TktI0kNZLhLUgMZ7pLUQIa7JDWQ4S5JDWS4S1IDeSukpONTv7+n8oHrujrt4osv5sEHH+T9738/3/jGN/pWjlfukjREn/70p/nqV7/a959ruEvSHJhuyd/du3ezZs0aTjrppL7357SMJM2B6Zb8PfvsswfWn+EuSXNk06ZNrF69mkWLFvGFL3xhoH05LSNJc+ToJX8HqZPH7N2aZH/7kXpH7/vNJJVk6ZS265LsSfJUkv6sXSlJDXD0kr+D1Mm0zG3AF4HbpzYmWQ6sBfZOaTsTWA+cResB2X+aZJXPUZX0ptPlrYvdmm7J3/vuu4/Nmzfz5JNP8sorrzA6Osott9zSlzXdO3mG6v1JVkyz62bgauDuKW3rgDur6jXguSR7gHNpPWBbko5bx1ry98ILLxxIf13NuSe5BHihqr5z1K5lwPNTtifabdP9jI1JxpOMT05OdlOGJOkYZh3uSd4K/Dawabrd07S98QmwQFVtqaqxqhobGRmZbRmSpJ+gmyv3nwFWAt9J8r+AUeAvkvwDWlfqy6ccOwq82GuRktQPVdNea77pdVP3rMO9qr5XVadU1YqqWkEr0N9bVX8JbAfWJ3lLkpXAGcBDs65Kkvps0aJFHDhwYN4FfFVx4MABFi1aNKvzZvxANckdwAXA0iQTwOaquuUYRTyWZBvwOHAYuNI7ZSS9GYyOjjIxMcF8/Ixv0aJFjI6OzuqcTu6W+egM+1cctX0DcMOsqpCkAVu4cCErV64cdhlzxm+oSlIDGe6S1ECGuyQ1kOEuSQ1kuEtSAxnuktRAhrskNZDhLkkNZLhLUgMZ7pLUQIa7JDWQ4S5JDWS4S1IDGe6S1ECGuyQ1kOEuSQ1kuEtSA80Y7kluTbI/ye4pbf8uyZNJvpvkPyd5x5R91yXZk+SpJBcNqG5J0k/QyZX7bcDFR7XtAM6uqnOAp4HrAJKcCawHzmqf8+UkJ/StWklSR2YM96q6Hzh4VNu9VXW4vfkg8PqTW9cBd1bVa1X1HLAHOLeP9UqSOtCPOfdPAH/cfr8MeH7Kvol2myRpDvUU7kl+GzgMfO31pmkOq2OcuzHJeJLxycnJXsqQJB2l63BPsgH4EHBpVb0e4BPA8imHjQIvTnd+VW2pqrGqGhsZGem2DEnSNLoK9yQXA9cAl1TV30zZtR1Yn+QtSVYCZwAP9V6mJGk2Fsx0QJI7gAuApUkmgM207o55C7AjCcCDVfVrVfVYkm3A47Sma66sqiODKl6SNL0Zw72qPjpN8y0/4fgbgBt6KUqS1Bu/oSpJDWS4S1IDGe6S1ECGuyQ1kOEuSQ1kuEtSAxnuktRAhrskNZDhLkkNZLhLUgMZ7pLUQIa7JDXQjAuH6c3nvL1bhtj7TUPsW1KnvHKXpAYy3CWpgQx3SWogw12SGsgPVDUrN+94eij9XrV21VD6learGa/ck9yaZH+S3VPaliTZkeSZ9uviKfuuS7InyVNJLhpU4ZKkY+tkWuY24OKj2q4FdlbVGcDO9jZJzgTWA2e1z/lykhP6Vq0kqSMzhntV3Q8cPKp5HbC1/X4r8OEp7XdW1WtV9RywBzi3P6VKkjrV7Qeqp1bVPoD26ynt9mXA81OOm2i3vUGSjUnGk4xPTk52WYYkaTr9vlsm07TVdAdW1ZaqGquqsZGRkT6XIUnHt27D/aUkpwG0X/e32yeA5VOOGwVe7L48SVI3ug337cCG9vsNwN1T2tcneUuSlcAZwEO9lShJmq0Z73NPcgdwAbA0yQSwGbgR2JbkCmAv8BGAqnosyTbgceAwcGVVHRlQ7ZKkY5gx3Kvqo8fYteYYx98A3NBLUZKk3rj8gCQ1kOEuSQ1kuEtSAxnuktRAhrskNZDhLkkNZLhLUgMZ7pLUQIa7JDWQ4S5JDWS4S1IDGe6S1ECGuyQ1kOEuSQ1kuEtSAxnuktRAhrskNVBP4Z7kqiSPJdmd5I4ki5IsSbIjyTPt18X9KlaS1Jmuwz3JMuA3gLGqOhs4AVgPXAvsrKozgJ3tbUnSHOp1WmYB8FNJFgBvBV4E1gFb2/u3Ah/usQ9J0ix1He5V9QJwE7AX2Af8VVXdC5xaVfvax+wDTpnu/CQbk4wnGZ+cnOy2DEnSNHqZlllM6yp9JXA68NNJLuv0/KraUlVjVTU2MjLSbRmSpGn0Mi3zT4Dnqmqyqn4E3AWcD7yU5DSA9uv+3suUJM1GL+G+FzgvyVuTBFgDPAFsBza0j9kA3N1biZKk2VrQ7YlVtSvJ14G/AA4D3wa2AG8DtiW5gtYfgI/0o1BJUue6DneAqtoMbD6q+TVaV/GSpCHxG6qS1ECGuyQ1kOEuSQ1kuEtSAxnuktRAhrskNZDhLkkNZLhLUgMZ7pLUQIa7JDWQ4S5JDWS4S1ID9bRwmI4/5+3dMqSebxpSv9L85JW7JDWQ4S5JDeS0TA8eePbAsEuQpGl55S5JDdRTuCd5R5KvJ3kyyRNJfj7JkiQ7kjzTfl3cr2IlSZ3p9cr994F7qupngffQekD2tcDOqjoD2NneliTNoa7DPcnbgV8CbgGoqr+tqv8DrAO2tg/bCny4txIlSbPVy5X7u4BJ4D8k+XaSryT5aeDUqtoH0H49ZbqTk2xMMp5kfHJysocyJElH6+VumQXAe4FPVtWuJL/PLKZgqmoLsAVgbGyseqgDvvk7PZ0uSU3Ty5X7BDBRVbva21+nFfYvJTkNoP26v7cSJUmz1XW4V9VfAs8neXe7aQ3wOLAd2NBu2wDc3VOFkqRZ6/VLTJ8EvpbkROBZ4OO0/mBsS3IFsBf4SI99SJJmqadwr6pHgbFpdq3p5edKknrjN1QlqYEMd0lqIMNdkhrIcJekBjLcJamBDHdJaiDDXZIayHCXpAYy3CWpgQx3SWogw12SGqjXhcOkOXHzjqeH1vdVa1cNrW+pW165S1IDGe6S1ECGuyQ1kOEuSQ1kuEtSA/Uc7klOSPLtJN9oby9JsiPJM+3Xxb2XKUmajX7cCvkp4Ang7e3ta4GdVXVjkmvb29f0oR8dx87bu2WIvd80xL6l7vR05Z5kFPinwFemNK8DtrbfbwU+3EsfkqTZ63Va5veAq4EfT2k7tar2AbRfT5nuxCQbk4wnGZ+cnOyxDEnSVF2He5IPAfur6pFuzq+qLVU1VlVjIyMj3ZYhSZpGL3PuvwBckuSDwCLg7Un+I/BSktOqal+S04D9/ShUGpZhLX3gsgfqRddX7lV1XVWNVtUKYD1wX1VdBmwHNrQP2wDc3XOVkqRZGcR97jcCa5M8A6xtb0uS5lBfVoWsqm8B32q/PwCs6cfPlSR1x2+oSlIDGe6S1ECGuyQ1kOEuSQ1kuEtSAxnuktRAhrskNVBf7nOX1H/DWvYAXPqgCbxyl6QGMtwlqYEMd0lqIMNdkhrIcJekBjLcJamBDHdJaiDDXZIayHCXpAbqOtyTLE/yzSRPJHksyafa7UuS7EjyTPt1cf/KlSR1opcr98PAv6mqnwPOA65MciZwLbCzqs4Adra3JUlzqOu1ZapqH7Cv/f4HSZ4AlgHrgAvah22l9WzVa3qqUhqi8/ZuGUq/D75z41D6VTP0Zc49yQrgHwG7gFPbwf/6H4BT+tGHJKlzPYd7krcBfwj866r661mctzHJeJLxycnJXsuQJE3RU7gnWUgr2L9WVXe1m19Kclp7/2nA/unOraotVTVWVWMjIyO9lCFJOkovd8sEuAV4oqp+d8qu7cCG9vsNwN3dlydJ6kYvD+v4BeBXge8lebTd9lvAjcC2JFcAe4GP9FShJGnWerlb5n8AOcbuNd3+XElS7xrxmL0Hnj0w7BIk6U3F5QckqYEMd0lqIMNdkhrIcJekBmrEB6pSEw1rTZuWm4bYt/rBK3dJaiDDXZIayHCXpAYy3CWpgQx3SWogw12SGshbISW9wc07nh5Kv1etXTWUfpvIK3dJaiDDXZIayHCXpAZyzl3SGwxr6YMHbhlKt/z8Fc1bbsErd0lqoIGFe5KLkzyVZE+SawfVjyTpjQYyLZPkBOBLwFpgAng4yfaqenwQ/UlSLx645TeH1vegpoQGdeV+LrCnqp6tqr8F7gTWDagvSdJRBvWB6jLg+SnbE8A/nnpAko3AxvbmK0me6qG/pcD3ezh/vjnexguO+Xhx/I35X/z7Xsb8D4+1Y1Dhnmna6v/bqNoC9OUj+STjVTXWj581Hxxv4wXHfLxwzP0zqGmZCWD5lO1R4MUB9SVJOsqgwv1h4IwkK5OcCKwHtg+oL0nSUQYyLVNVh5P8OvAnwAnArVX12CD6ahvmwyaH4XgbLzjm44Vj7pNU1cxHSZLmFb+hKkkNZLhLUgPNm3CfaTmDtHyhvf+7Sd47jDr7qYMxX9oe63eT/HmS9wyjzn7qdNmKJKuTHEnyK3NZ3yB0MuYkFyR5NMljSf5srmvstw5+t/9+kv+S5DvtMX98GHX2S5Jbk+xPsvsY+/ufX1X1pv+P1oey/xN4F3Ai8B3gzKOO+SDwx7TusT8P2DXsuudgzOcDi9vvf/l4GPOU4+4D/hvwK8Ouew7+nd8BPA68s719yrDrnoMx/xbwb9vvR4CDwInDrr2HMf8S8F5g9zH29z2/5suVeyfLGawDbq+WB4F3JDltrgvtoxnHXFV/XlUvtzcfpPV9gvms02UrPgn8IbB/LosbkE7G/DHgrqraC1BV833cnYy5gJOSBHgbrXA/PLdl9k9V3U9rDMfS9/yaL+E+3XIGy7o4Zj6Z7XiuoPWXfz6bccxJlgH/DPiDOaxrkDr5d14FLE7yrSSPJLl8zqobjE7G/EXg52h9+fF7wKeq6sdzU95Q9D2/5svDOmZczqDDY+aTjseT5AO0wv39A61o8DoZ8+8B11TVkdZF3bzXyZgXAO8D1gA/BTyQ5MGqGs5TrHvXyZgvAh4FLgR+BtiR5L9X1V8PuLZh6Xt+zZdw72Q5g6YtedDReJKcA3wF+OWqOjBHtQ1KJ2MeA+5sB/tS4INJDlfVH81Jhf3X6e/296vqVeDVJPcD7wHma7h3MuaPAzdWa0J6T5LngJ8FHpqbEudc3/NrvkzLdLKcwXbg8vanzucBf1VV++a60D6accxJ3gncBfzqPL6Km2rGMVfVyqpaUVUrgK8D/2oeBzt09rt9N/CLSRYkeSutFVafmOM6+6mTMe+l9X8qJDkVeDfw7JxWObf6nl/z4sq9jrGcQZJfa+//A1p3TnwQ2AP8Da2//PNWh2PeBJwMfLl9JXu45vGKeh2OuVE6GXNVPZHkHuC7wI+Br1TVtLfUzQcd/jt/DrgtyfdoTVlcU1XzdingJHcAFwBLk0wAm4GFMLj8cvkBSWqg+TItI0maBcNdkhrIcJekBjLcJamBDHdJaiDDXZIayHCXpAb6vx55j37kCMjaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_dev_scaled[:,0], alpha=.5, label='x0')\n",
    "plt.hist(X_dev_scaled[:,5], alpha=.5, label='x1')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x0000026A55A74510>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  1,   2,   3,   4,   5,   6,   7,   8,  10,  12,  13,  14,  16,\n",
       "          17,  20,  21,  22,  23,  24,  26,  27,  28,  29,  31,  32,  34,\n",
       "          35,  36,  37,  38,  40,  41,  43,  44,  45,  46,  47,  48,  49,\n",
       "          50,  51,  52,  53,  54,  57,  58,  59,  60,  61,  62,  64,  65,\n",
       "          66,  67,  68,  69,  71,  74,  80,  81,  83,  84,  85,  86,  87,\n",
       "          88,  89,  91,  92,  94,  95,  96,  97,  98,  99, 100, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 118,\n",
       "         119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 133, 134,\n",
       "         135, 136, 138, 139, 141, 142, 143, 144, 145, 146, 147, 149, 150,\n",
       "         151, 152, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 174, 176, 177, 178, 179, 181, 182, 183,\n",
       "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
       "         198, 199, 200, 201, 202, 204, 205, 206, 207, 209, 211, 212, 213,\n",
       "         214, 215, 216, 217, 219, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "         230, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244,\n",
       "         245, 246, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273,\n",
       "         274, 275, 276, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288,\n",
       "         289, 290, 291, 292, 293, 294, 295, 299, 300, 303, 305, 306, 307,\n",
       "         308, 309, 310, 313, 314, 315, 316, 317, 318, 319, 320, 322, 323,\n",
       "         324, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366,\n",
       "         367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "         380, 381, 383, 385, 387, 388, 389, 390, 391, 392, 394, 395, 396,\n",
       "         397, 399, 401, 403, 404, 405, 407, 409, 410, 411, 413, 414, 416,\n",
       "         417, 419, 420, 421, 422, 423, 424, 427, 428, 430, 431, 432, 433,\n",
       "         435, 436, 437, 438, 439, 441, 444, 447, 448, 449, 450, 451, 452,\n",
       "         453, 455, 457, 458, 459, 461, 462, 465, 466, 467, 468]),\n",
       "  array([  0,   9,  11,  15,  18,  19,  25,  30,  33,  39,  42,  55,  56,\n",
       "          63,  70,  72,  73,  75,  76,  77,  78,  79,  82,  90,  93, 101,\n",
       "         113, 117, 124, 131, 132, 137, 140, 148, 153, 154, 155, 157, 173,\n",
       "         175, 180, 196, 203, 208, 210, 218, 220, 229, 231, 238, 247, 248,\n",
       "         271, 277, 284, 296, 297, 298, 301, 302, 304, 311, 312, 321, 331,\n",
       "         352, 362, 364, 382, 384, 386, 393, 398, 400, 402, 406, 408, 412,\n",
       "         415, 418, 425, 426, 429, 434, 440, 442, 443, 445, 446, 454, 456,\n",
       "         460, 463, 464])),\n",
       " (array([  0,   1,   2,   4,   6,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "          18,  19,  20,  21,  23,  25,  27,  28,  30,  32,  33,  34,  35,\n",
       "          36,  37,  38,  39,  40,  41,  42,  43,  44,  47,  48,  49,  50,\n",
       "          51,  52,  53,  54,  55,  56,  58,  59,  61,  62,  63,  64,  65,\n",
       "          67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,  79,  80,\n",
       "          81,  82,  85,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 105, 106, 107, 111, 112, 113, 115,\n",
       "         117, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 147,\n",
       "         148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
       "         162, 163, 164, 166, 167, 169, 170, 171, 173, 174, 175, 177, 178,\n",
       "         179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 194, 195,\n",
       "         196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210,\n",
       "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "         224, 225, 226, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238,\n",
       "         240, 241, 242, 243, 246, 247, 248, 251, 252, 253, 254, 255, 256,\n",
       "         257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270,\n",
       "         271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284,\n",
       "         285, 286, 288, 289, 291, 292, 293, 295, 296, 297, 298, 300, 301,\n",
       "         302, 303, 304, 306, 308, 309, 310, 311, 312, 313, 315, 317, 319,\n",
       "         320, 321, 322, 325, 326, 327, 328, 329, 330, 331, 334, 337, 338,\n",
       "         339, 340, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353,\n",
       "         355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 368, 372,\n",
       "         373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386,\n",
       "         387, 389, 390, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 405, 406, 407, 408, 409, 410, 412, 413, 415, 416, 417, 418,\n",
       "         419, 421, 422, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434,\n",
       "         435, 436, 440, 441, 442, 443, 444, 445, 446, 447, 451, 452, 453,\n",
       "         454, 455, 456, 457, 458, 460, 461, 463, 464, 465, 468]),\n",
       "  array([  3,   5,   7,  16,  17,  22,  24,  26,  29,  31,  45,  46,  57,\n",
       "          60,  66,  74,  83,  84,  86,  94, 104, 108, 109, 110, 114, 116,\n",
       "         118, 119, 126, 141, 145, 152, 165, 168, 172, 176, 181, 185, 192,\n",
       "         193, 199, 209, 227, 234, 239, 244, 245, 249, 250, 262, 280, 287,\n",
       "         290, 294, 299, 305, 307, 314, 316, 318, 323, 324, 332, 333, 335,\n",
       "         336, 341, 346, 354, 358, 367, 369, 370, 371, 378, 388, 391, 394,\n",
       "         404, 411, 414, 420, 427, 428, 437, 438, 439, 448, 449, 450, 459,\n",
       "         462, 466, 467])),\n",
       " (array([  0,   1,   3,   4,   5,   7,   8,   9,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  34,  35,  39,  40,  41,  42,  43,  44,  45,\n",
       "          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "          60,  61,  62,  63,  64,  65,  66,  70,  71,  72,  73,  74,  75,\n",
       "          76,  77,  78,  79,  80,  82,  83,  84,  85,  86,  87,  88,  90,\n",
       "          91,  93,  94,  95,  98,  99, 100, 101, 102, 104, 105, 106, 107,\n",
       "         108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124,\n",
       "         126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140,\n",
       "         141, 142, 145, 148, 149, 151, 152, 153, 154, 155, 156, 157, 159,\n",
       "         160, 161, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174,\n",
       "         175, 176, 178, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "         193, 196, 197, 199, 200, 201, 203, 205, 206, 207, 208, 209, 210,\n",
       "         212, 213, 214, 215, 216, 217, 218, 220, 221, 224, 226, 227, 229,\n",
       "         230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243,\n",
       "         244, 245, 247, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259,\n",
       "         260, 262, 263, 264, 267, 269, 270, 271, 273, 276, 277, 279, 280,\n",
       "         282, 283, 284, 285, 287, 288, 290, 292, 293, 294, 295, 296, 297,\n",
       "         298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 326,\n",
       "         327, 328, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 357, 358, 359,\n",
       "         362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 374, 376, 378,\n",
       "         380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394,\n",
       "         396, 398, 400, 401, 402, 403, 404, 405, 406, 408, 409, 411, 412,\n",
       "         413, 414, 415, 416, 418, 419, 420, 421, 422, 423, 425, 426, 427,\n",
       "         428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456,\n",
       "         458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468]),\n",
       "  array([  2,   6,  10,  23,  36,  37,  38,  59,  67,  68,  69,  81,  89,\n",
       "          92,  96,  97, 103, 111, 112, 122, 123, 125, 129, 139, 143, 144,\n",
       "         146, 147, 150, 158, 163, 167, 177, 179, 182, 183, 184, 194, 195,\n",
       "         198, 202, 204, 211, 219, 222, 223, 225, 228, 237, 246, 253, 255,\n",
       "         261, 265, 266, 268, 272, 274, 275, 278, 281, 286, 289, 291, 310,\n",
       "         320, 325, 329, 334, 338, 347, 353, 355, 356, 360, 361, 365, 373,\n",
       "         375, 377, 379, 383, 392, 395, 397, 399, 407, 410, 417, 424, 441,\n",
       "         452, 455, 457])),\n",
       " (array([  0,   1,   2,   3,   5,   6,   7,   9,  10,  11,  13,  15,  16,\n",
       "          17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  29,  30,  31,\n",
       "          33,  34,  36,  37,  38,  39,  42,  43,  45,  46,  48,  49,  50,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  63,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  86,  87,  88,  89,  90,  91,  92,  93,  94,  96,\n",
       "          97,  99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112,\n",
       "         113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 129,\n",
       "         130, 131, 132, 134, 137, 139, 140, 141, 143, 144, 145, 146, 147,\n",
       "         148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 160, 161, 163,\n",
       "         165, 166, 167, 168, 169, 172, 173, 174, 175, 176, 177, 179, 180,\n",
       "         181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 198, 199, 201, 202, 203, 204, 205, 207, 208, 209, 210,\n",
       "         211, 212, 214, 217, 218, 219, 220, 222, 223, 225, 227, 228, 229,\n",
       "         231, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 246, 247,\n",
       "         248, 249, 250, 251, 252, 253, 255, 257, 259, 261, 262, 263, 264,\n",
       "         265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
       "         280, 281, 284, 286, 287, 289, 290, 291, 293, 294, 295, 296, 297,\n",
       "         298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 318, 319, 320, 321, 323, 324, 325, 328,\n",
       "         329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 341, 343, 344,\n",
       "         345, 346, 347, 348, 350, 352, 353, 354, 355, 356, 358, 359, 360,\n",
       "         361, 362, 363, 364, 365, 366, 367, 369, 370, 371, 372, 373, 375,\n",
       "         377, 378, 379, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392,\n",
       "         393, 394, 395, 397, 398, 399, 400, 402, 404, 406, 407, 408, 410,\n",
       "         411, 412, 413, 414, 415, 416, 417, 418, 420, 424, 425, 426, 427,\n",
       "         428, 429, 430, 431, 434, 435, 437, 438, 439, 440, 441, 442, 443,\n",
       "         444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
       "         458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468]),\n",
       "  array([  4,   8,  12,  14,  27,  28,  32,  35,  40,  41,  44,  47,  51,\n",
       "          61,  62,  64,  65,  85,  95,  98, 100, 107, 115, 120, 127, 128,\n",
       "         133, 135, 136, 138, 142, 156, 159, 162, 164, 170, 171, 178, 186,\n",
       "         197, 200, 206, 213, 215, 216, 221, 224, 226, 230, 232, 233, 240,\n",
       "         242, 254, 256, 258, 260, 267, 279, 282, 283, 285, 288, 292, 300,\n",
       "         317, 322, 326, 327, 337, 340, 342, 349, 351, 357, 368, 374, 376,\n",
       "         380, 381, 390, 396, 401, 403, 405, 409, 419, 421, 422, 423, 432,\n",
       "         433, 436, 447])),\n",
       " (array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
       "          15,  16,  17,  18,  19,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  44,\n",
       "          45,  46,  47,  51,  55,  56,  57,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,\n",
       "          79,  81,  82,  83,  84,  85,  86,  89,  90,  92,  93,  94,  95,\n",
       "          96,  97,  98, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112,\n",
       "         113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
       "         127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141,\n",
       "         142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156,\n",
       "         157, 158, 159, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173,\n",
       "         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 192,\n",
       "         193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 208,\n",
       "         209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224,\n",
       "         225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 237, 238, 239,\n",
       "         240, 242, 244, 245, 246, 247, 248, 249, 250, 253, 254, 255, 256,\n",
       "         258, 260, 261, 262, 265, 266, 267, 268, 271, 272, 274, 275, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307,\n",
       "         310, 311, 312, 314, 316, 317, 318, 320, 321, 322, 323, 324, 325,\n",
       "         326, 327, 329, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341,\n",
       "         342, 346, 347, 349, 351, 352, 353, 354, 355, 356, 357, 358, 360,\n",
       "         361, 362, 364, 365, 367, 368, 369, 370, 371, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 390, 391, 392,\n",
       "         393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 414, 415, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 436,\n",
       "         437, 438, 439, 440, 441, 442, 443, 445, 446, 447, 448, 449, 450,\n",
       "         452, 454, 455, 456, 457, 459, 460, 462, 463, 464, 466, 467]),\n",
       "  array([  1,  13,  20,  21,  34,  43,  48,  49,  50,  52,  53,  54,  58,\n",
       "          71,  80,  87,  88,  91,  99, 102, 105, 106, 121, 130, 134, 149,\n",
       "         151, 160, 161, 166, 169, 174, 187, 188, 189, 190, 191, 201, 205,\n",
       "         207, 212, 214, 217, 235, 236, 241, 243, 251, 252, 257, 259, 263,\n",
       "         264, 269, 270, 273, 276, 293, 295, 303, 306, 308, 309, 313, 315,\n",
       "         319, 328, 330, 339, 343, 344, 345, 348, 350, 359, 363, 366, 372,\n",
       "         385, 387, 389, 413, 416, 430, 431, 435, 444, 451, 453, 458, 461,\n",
       "         465, 468]))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kfold.split(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x0000026A55A74C80>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stkfold.split(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  1,   2,   3,   4,   5,   6,   7,   8,  10,  12,  13,  14,  16,\n",
       "          17,  20,  21,  22,  23,  24,  26,  27,  28,  29,  31,  32,  34,\n",
       "          35,  36,  37,  38,  40,  41,  43,  44,  45,  46,  47,  48,  49,\n",
       "          50,  51,  52,  53,  54,  57,  58,  59,  60,  61,  62,  64,  65,\n",
       "          66,  67,  68,  69,  71,  74,  80,  81,  83,  84,  85,  86,  87,\n",
       "          88,  89,  91,  92,  94,  95,  96,  97,  98,  99, 100, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 118,\n",
       "         119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 133, 134,\n",
       "         135, 136, 138, 139, 141, 142, 143, 144, 145, 146, 147, 149, 150,\n",
       "         151, 152, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 174, 176, 177, 178, 179, 181, 182, 183,\n",
       "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
       "         198, 199, 200, 201, 202, 204, 205, 206, 207, 209, 211, 212, 213,\n",
       "         214, 215, 216, 217, 219, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "         230, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244,\n",
       "         245, 246, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273,\n",
       "         274, 275, 276, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288,\n",
       "         289, 290, 291, 292, 293, 294, 295, 299, 300, 303, 305, 306, 307,\n",
       "         308, 309, 310, 313, 314, 315, 316, 317, 318, 319, 320, 322, 323,\n",
       "         324, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366,\n",
       "         367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "         380, 381, 383, 385, 387, 388, 389, 390, 391, 392, 394, 395, 396,\n",
       "         397, 399, 401, 403, 404, 405, 407, 409, 410, 411, 413, 414, 416,\n",
       "         417, 419, 420, 421, 422, 423, 424, 427, 428, 430, 431, 432, 433,\n",
       "         435, 436, 437, 438, 439, 441, 444, 447, 448, 449, 450, 451, 452,\n",
       "         453, 455, 457, 458, 459, 461, 462, 465, 466, 467, 468]),\n",
       "  array([  0,   9,  11,  15,  18,  19,  25,  30,  33,  39,  42,  55,  56,\n",
       "          63,  70,  72,  73,  75,  76,  77,  78,  79,  82,  90,  93, 101,\n",
       "         113, 117, 124, 131, 132, 137, 140, 148, 153, 154, 155, 157, 173,\n",
       "         175, 180, 196, 203, 208, 210, 218, 220, 229, 231, 238, 247, 248,\n",
       "         271, 277, 284, 296, 297, 298, 301, 302, 304, 311, 312, 321, 331,\n",
       "         352, 362, 364, 382, 384, 386, 393, 398, 400, 402, 406, 408, 412,\n",
       "         415, 418, 425, 426, 429, 434, 440, 442, 443, 445, 446, 454, 456,\n",
       "         460, 463, 464])),\n",
       " (array([  0,   1,   2,   4,   6,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "          18,  19,  20,  21,  23,  25,  27,  28,  30,  32,  33,  34,  35,\n",
       "          36,  37,  38,  39,  40,  41,  42,  43,  44,  47,  48,  49,  50,\n",
       "          51,  52,  53,  54,  55,  56,  58,  59,  61,  62,  63,  64,  65,\n",
       "          67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,  79,  80,\n",
       "          81,  82,  85,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 105, 106, 107, 111, 112, 113, 115,\n",
       "         117, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 147,\n",
       "         148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
       "         162, 163, 164, 166, 167, 169, 170, 171, 173, 174, 175, 177, 178,\n",
       "         179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 194, 195,\n",
       "         196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210,\n",
       "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "         224, 225, 226, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238,\n",
       "         240, 241, 242, 243, 246, 247, 248, 251, 252, 253, 254, 255, 256,\n",
       "         257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270,\n",
       "         271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284,\n",
       "         285, 286, 288, 289, 291, 292, 293, 295, 296, 297, 298, 300, 301,\n",
       "         302, 303, 304, 306, 308, 309, 310, 311, 312, 313, 315, 317, 319,\n",
       "         320, 321, 322, 325, 326, 327, 328, 329, 330, 331, 334, 337, 338,\n",
       "         339, 340, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353,\n",
       "         355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 368, 372,\n",
       "         373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386,\n",
       "         387, 389, 390, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 405, 406, 407, 408, 409, 410, 412, 413, 415, 416, 417, 418,\n",
       "         419, 421, 422, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434,\n",
       "         435, 436, 440, 441, 442, 443, 444, 445, 446, 447, 451, 452, 453,\n",
       "         454, 455, 456, 457, 458, 460, 461, 463, 464, 465, 468]),\n",
       "  array([  3,   5,   7,  16,  17,  22,  24,  26,  29,  31,  45,  46,  57,\n",
       "          60,  66,  74,  83,  84,  86,  94, 104, 108, 109, 110, 114, 116,\n",
       "         118, 119, 126, 141, 145, 152, 165, 168, 172, 176, 181, 185, 192,\n",
       "         193, 199, 209, 227, 234, 239, 244, 245, 249, 250, 262, 280, 287,\n",
       "         290, 294, 299, 305, 307, 314, 316, 318, 323, 324, 332, 333, 335,\n",
       "         336, 341, 346, 354, 358, 367, 369, 370, 371, 378, 388, 391, 394,\n",
       "         404, 411, 414, 420, 427, 428, 437, 438, 439, 448, 449, 450, 459,\n",
       "         462, 466, 467])),\n",
       " (array([  0,   1,   3,   4,   5,   7,   8,   9,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  34,  35,  39,  40,  41,  42,  43,  44,  45,\n",
       "          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "          60,  61,  62,  63,  64,  65,  66,  70,  71,  72,  73,  74,  75,\n",
       "          76,  77,  78,  79,  80,  82,  83,  84,  85,  86,  87,  88,  90,\n",
       "          91,  93,  94,  95,  98,  99, 100, 101, 102, 104, 105, 106, 107,\n",
       "         108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124,\n",
       "         126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140,\n",
       "         141, 142, 145, 148, 149, 151, 152, 153, 154, 155, 156, 157, 159,\n",
       "         160, 161, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174,\n",
       "         175, 176, 178, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "         193, 196, 197, 199, 200, 201, 203, 205, 206, 207, 208, 209, 210,\n",
       "         212, 213, 214, 215, 216, 217, 218, 220, 221, 224, 226, 227, 229,\n",
       "         230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243,\n",
       "         244, 245, 247, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259,\n",
       "         260, 262, 263, 264, 267, 269, 270, 271, 273, 276, 277, 279, 280,\n",
       "         282, 283, 284, 285, 287, 288, 290, 292, 293, 294, 295, 296, 297,\n",
       "         298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 326,\n",
       "         327, 328, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 357, 358, 359,\n",
       "         362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 374, 376, 378,\n",
       "         380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394,\n",
       "         396, 398, 400, 401, 402, 403, 404, 405, 406, 408, 409, 411, 412,\n",
       "         413, 414, 415, 416, 418, 419, 420, 421, 422, 423, 425, 426, 427,\n",
       "         428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456,\n",
       "         458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468]),\n",
       "  array([  2,   6,  10,  23,  36,  37,  38,  59,  67,  68,  69,  81,  89,\n",
       "          92,  96,  97, 103, 111, 112, 122, 123, 125, 129, 139, 143, 144,\n",
       "         146, 147, 150, 158, 163, 167, 177, 179, 182, 183, 184, 194, 195,\n",
       "         198, 202, 204, 211, 219, 222, 223, 225, 228, 237, 246, 253, 255,\n",
       "         261, 265, 266, 268, 272, 274, 275, 278, 281, 286, 289, 291, 310,\n",
       "         320, 325, 329, 334, 338, 347, 353, 355, 356, 360, 361, 365, 373,\n",
       "         375, 377, 379, 383, 392, 395, 397, 399, 407, 410, 417, 424, 441,\n",
       "         452, 455, 457])),\n",
       " (array([  0,   1,   2,   3,   5,   6,   7,   9,  10,  11,  13,  15,  16,\n",
       "          17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  29,  30,  31,\n",
       "          33,  34,  36,  37,  38,  39,  42,  43,  45,  46,  48,  49,  50,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  63,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  86,  87,  88,  89,  90,  91,  92,  93,  94,  96,\n",
       "          97,  99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112,\n",
       "         113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 129,\n",
       "         130, 131, 132, 134, 137, 139, 140, 141, 143, 144, 145, 146, 147,\n",
       "         148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 160, 161, 163,\n",
       "         165, 166, 167, 168, 169, 172, 173, 174, 175, 176, 177, 179, 180,\n",
       "         181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 198, 199, 201, 202, 203, 204, 205, 207, 208, 209, 210,\n",
       "         211, 212, 214, 217, 218, 219, 220, 222, 223, 225, 227, 228, 229,\n",
       "         231, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 246, 247,\n",
       "         248, 249, 250, 251, 252, 253, 255, 257, 259, 261, 262, 263, 264,\n",
       "         265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
       "         280, 281, 284, 286, 287, 289, 290, 291, 293, 294, 295, 296, 297,\n",
       "         298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 318, 319, 320, 321, 323, 324, 325, 328,\n",
       "         329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 341, 343, 344,\n",
       "         345, 346, 347, 348, 350, 352, 353, 354, 355, 356, 358, 359, 360,\n",
       "         361, 362, 363, 364, 365, 366, 367, 369, 370, 371, 372, 373, 375,\n",
       "         377, 378, 379, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392,\n",
       "         393, 394, 395, 397, 398, 399, 400, 402, 404, 406, 407, 408, 410,\n",
       "         411, 412, 413, 414, 415, 416, 417, 418, 420, 424, 425, 426, 427,\n",
       "         428, 429, 430, 431, 434, 435, 437, 438, 439, 440, 441, 442, 443,\n",
       "         444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
       "         458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468]),\n",
       "  array([  4,   8,  12,  14,  27,  28,  32,  35,  40,  41,  44,  47,  51,\n",
       "          61,  62,  64,  65,  85,  95,  98, 100, 107, 115, 120, 127, 128,\n",
       "         133, 135, 136, 138, 142, 156, 159, 162, 164, 170, 171, 178, 186,\n",
       "         197, 200, 206, 213, 215, 216, 221, 224, 226, 230, 232, 233, 240,\n",
       "         242, 254, 256, 258, 260, 267, 279, 282, 283, 285, 288, 292, 300,\n",
       "         317, 322, 326, 327, 337, 340, 342, 349, 351, 357, 368, 374, 376,\n",
       "         380, 381, 390, 396, 401, 403, 405, 409, 419, 421, 422, 423, 432,\n",
       "         433, 436, 447])),\n",
       " (array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
       "          15,  16,  17,  18,  19,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  44,\n",
       "          45,  46,  47,  51,  55,  56,  57,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,\n",
       "          79,  81,  82,  83,  84,  85,  86,  89,  90,  92,  93,  94,  95,\n",
       "          96,  97,  98, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112,\n",
       "         113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126,\n",
       "         127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141,\n",
       "         142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156,\n",
       "         157, 158, 159, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173,\n",
       "         175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 192,\n",
       "         193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 208,\n",
       "         209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224,\n",
       "         225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 237, 238, 239,\n",
       "         240, 242, 244, 245, 246, 247, 248, 249, 250, 253, 254, 255, 256,\n",
       "         258, 260, 261, 262, 265, 266, 267, 268, 271, 272, 274, 275, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307,\n",
       "         310, 311, 312, 314, 316, 317, 318, 320, 321, 322, 323, 324, 325,\n",
       "         326, 327, 329, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341,\n",
       "         342, 346, 347, 349, 351, 352, 353, 354, 355, 356, 357, 358, 360,\n",
       "         361, 362, 364, 365, 367, 368, 369, 370, 371, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 390, 391, 392,\n",
       "         393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 414, 415, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 436,\n",
       "         437, 438, 439, 440, 441, 442, 443, 445, 446, 447, 448, 449, 450,\n",
       "         452, 454, 455, 456, 457, 459, 460, 462, 463, 464, 466, 467]),\n",
       "  array([  1,  13,  20,  21,  34,  43,  48,  49,  50,  52,  53,  54,  58,\n",
       "          71,  80,  87,  88,  91,  99, 102, 105, 106, 121, 130, 134, 149,\n",
       "         151, 160, 161, 166, 169, 174, 187, 188, 189, 190, 191, 201, 205,\n",
       "         207, 212, 214, 217, 235, 236, 241, 243, 251, 252, 257, 259, 263,\n",
       "         264, 269, 270, 273, 276, 293, 295, 303, 306, 308, 309, 313, 315,\n",
       "         319, 328, 330, 339, 343, 344, 345, 348, 350, 359, 363, 366, 372,\n",
       "         385, 387, 389, 413, 416, 430, 431, 435, 444, 451, 453, 458, 461,\n",
       "         465, 468]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kfold.split(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_kfold = KFold(n_splits=10)\n",
    "inner_kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selection_indices, tets_indices in outer_kfold.split(X, y):\n",
    "    for train_indices, validation_indicesin inner_kfold.split(X[selection_indices], y[selection_indices]):\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking into asccount std in validation curve with k-nn is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using param-grid for grid search or random search\n",
    "## --- in grid search indicate scoring ='balanced_accuracy' in cv = kfold...\n",
    "## --- in the results we have cv_result, best_estimators,  best_score, best_parameter\n",
    "## euclidean or manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random search is better for larger number of parameter to tune, so e.g. for NN it's better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeClassifier(alpha = 1.0,\n",
    "        class_weight='balanced', \n",
    "        solver='auto')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(\n",
    "    hidden_layer_sizes=(5,)\n",
    "    ,activation='tanh'\n",
    "    ,solver='sdg'\n",
    "    ,alpha=1e-4\n",
    "    ,max_iter=50\n",
    "    ,shuffle=True\n",
    "    ,learning_rate=\n",
    "    ,learning_rate_init=\n",
    "    ,momentum=\n",
    "    ,nesterovs_momentum=\n",
    "    ,verbose=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(\n",
    "    C=1.0\n",
    "    ,kernel='linear'\n",
    "    ,class_weight='balanced'\n",
    "    ,verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear', verbose=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 31])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(\n",
    "    C=1.0\n",
    "    ,kernel='linear'\n",
    "    ,class_weight='balanced'\n",
    "    ,verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear', verbose=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, random_state=42,\n",
       "    verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, random_state=42,\n",
       "    verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, class_weight='balanced', kernel='linear', random_state=42,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a svm Classifier\n",
    "clf = SVC(\n",
    "   kernel='linear'\n",
    "  ,class_weight='balanced'\n",
    "  ,verbose=True\n",
    "  ,random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "param_grid = [\n",
    "  {'C': [0.1, 1, 10, 100], \n",
    "    'kernel': ['linear', 'rbf', 'poly']}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, n_jobs=20)\n",
    "grid_search.fit(X_dev, y_dev)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.25099173e+00, 4.84702110e-02, 9.96804237e-03, 8.63427973e+00,\n",
       "        3.92244816e-02, 3.55099678e-02, 3.21967669e+01, 1.10421658e-02,\n",
       "        5.51563263e-02, 4.51442835e+01, 2.10669899e-01, 7.19779968e-02]),\n",
       " 'std_fit_time': array([1.07882366e+00, 4.85019165e-02, 3.13658386e-03, 2.85771394e+00,\n",
       "        6.04811200e-02, 2.20644764e-02, 7.86483133e+00, 4.21314613e-03,\n",
       "        7.57557001e-02, 5.37603475e+00, 2.50689968e-01, 1.26918218e-01]),\n",
       " 'mean_score_time': array([0.00059843, 0.00539451, 0.00119686, 0.00339599, 0.01252627,\n",
       "        0.00139771, 0.00079818, 0.01507196, 0.00222936, 0.00152054,\n",
       "        0.00462823, 0.00121484]),\n",
       " 'std_score_time': array([0.00048862, 0.00049946, 0.0003984 , 0.00435031, 0.01377148,\n",
       "        0.00079741, 0.00074672, 0.02316674, 0.00304388, 0.00104194,\n",
       "        0.00323388, 0.00043459]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'poly', 'linear', 'rbf', 'poly',\n",
       "                    'linear', 'rbf', 'poly', 'linear', 'rbf', 'poly'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'poly'},\n",
       "  {'C': 100, 'kernel': 'linear'},\n",
       "  {'C': 100, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'kernel': 'poly'}],\n",
       " 'split0_test_score': array([0.95744681, 0.92553191, 0.89361702, 0.95744681, 0.91489362,\n",
       "        0.91489362, 0.9787234 , 0.94680851, 0.90425532, 0.96808511,\n",
       "        0.95744681, 0.95744681]),\n",
       " 'split1_test_score': array([0.92553191, 0.94680851, 0.94680851, 0.94680851, 0.91489362,\n",
       "        0.94680851, 0.96808511, 0.92553191, 0.92553191, 0.96808511,\n",
       "        0.93617021, 0.93617021]),\n",
       " 'split2_test_score': array([0.92553191, 0.82978723, 0.82978723, 0.93617021, 0.86170213,\n",
       "        0.85106383, 0.93617021, 0.88297872, 0.87234043, 0.94680851,\n",
       "        0.91489362, 0.91489362]),\n",
       " 'split3_test_score': array([0.96808511, 0.92553191, 0.92553191, 0.95744681, 0.92553191,\n",
       "        0.92553191, 0.94680851, 0.95744681, 0.95744681, 0.96808511,\n",
       "        0.95744681, 0.96808511]),\n",
       " 'split4_test_score': array([0.93548387, 0.93548387, 0.93548387, 0.94623656, 0.87096774,\n",
       "        0.90322581, 0.97849462, 0.91397849, 0.89247312, 0.95698925,\n",
       "        0.93548387, 0.92473118]),\n",
       " 'mean_test_score': array([0.94241592, 0.91262869, 0.90624571, 0.94882178, 0.8975978 ,\n",
       "        0.90830474, 0.96165637, 0.92534889, 0.91040952, 0.96161062,\n",
       "        0.94028826, 0.94026539]),\n",
       " 'std_test_score': array([0.01733798, 0.04215759, 0.0421368 , 0.00799476, 0.02598563,\n",
       "        0.03201577, 0.01724031, 0.02613558, 0.02915489, 0.00855823,\n",
       "        0.01596095, 0.0198542 ]),\n",
       " 'rank_test_score': array([ 4,  8, 11,  3, 12, 10,  1,  7,  9,  2,  5,  6])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.21279001235962"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.refit_time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_search.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__break_ties': False,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': 'balanced',\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'scale',\n",
       " 'estimator__kernel': 'linear',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': 42,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': True,\n",
       " 'estimator': SVC(class_weight='balanced', kernel='linear', random_state=42, verbose=True),\n",
       " 'n_jobs': 20,\n",
       " 'param_grid': [{'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly']}],\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.97\n",
      "F1-score [0.95890411 0.97637795]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        37\n",
      "           1       0.97      0.98      0.98        63\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.97      0.97      0.97       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 42,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1. , 0.9, 0.8, 1. , 0.8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_test, y_pred, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
